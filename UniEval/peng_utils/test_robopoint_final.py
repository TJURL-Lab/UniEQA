"""
RoboPointæµ‹è¯•ç±» - æœ€ç»ˆç®€åŒ–ç‰ˆï¼Œä½¿ç”¨å®˜æ–¹å®ç°ï¼Œæ”¯æŒå¤šGPU
"""
import os
import sys
import torch
import numpy as np
from PIL import Image
import threading

# æ·»åŠ å¿…è¦çš„å¯¼å…¥
from transformers import AutoTokenizer, AutoModelForCausalLM, AutoConfig, BitsAndBytesConfig
from transformers import StoppingCriteria

# ç®€å•å›¾åƒå¤„ç†å™¨
class SimpleImageProcessor:
    def __init__(self):
        self.image_mean = [0.48145466, 0.4578275, 0.40821073]
        self.image_std = [0.26862954, 0.26130258, 0.27577711]
        self.size = {"height": 336, "width": 336}

    def __call__(self, images, return_tensors='pt'):
        if isinstance(images, list):
            images = [self.process_single_image(img) for img in images]
            images = torch.stack(images)
        else:
            images = self.process_single_image(images)
        return {"pixel_values": images}

    def process_single_image(self, image):
        if isinstance(image, Image.Image):
            image = image.resize((self.size["width"], self.size["height"]))
            image = np.array(image).astype(np.float32) / 255.0
            image = (image - self.image_mean) / self.image_std
            image = torch.from_numpy(image).permute(2, 0, 1)
        return image

def load_model_official_way(model_path, model_name, device="auto", dtype=torch.bfloat16):
    """ä½¿ç”¨å®˜æ–¹æ–¹å¼åŠ è½½RoboPointæ¨¡å‹"""
    print(f"ğŸ“¥ ä½¿ç”¨å®˜æ–¹æ–¹å¼åŠ è½½RoboPointæ¨¡å‹: {model_path}")
    
    # å¯¼å…¥å®˜æ–¹builder
    sys.path.append('/home/fx/Exp2/video_model/RoboPoint')
    from robopoint.model.builder import load_pretrained_model
    
    try:
        # ä½¿ç”¨å®˜æ–¹çš„load_pretrained_modelå‡½æ•°
        tokenizer, model, image_processor, context_len = load_pretrained_model(
            model_path=model_path,
            model_base=None,
            model_name=model_name,
            load_8bit=False,
            load_4bit=False,
            device_map=device,  # "auto" æˆ–å…·ä½“è®¾å¤‡
            device="cuda",
            use_flash_attn=False
        )
        
        print("âœ… ä½¿ç”¨å®˜æ–¹æ–¹å¼åŠ è½½æˆåŠŸ")
        return tokenizer, model, image_processor, {"context_len": context_len}
        
    except Exception as e:
        print(f"âŒ å®˜æ–¹æ–¹å¼åŠ è½½å¤±è´¥: {e}")
        raise e

class TestRoboPoint:
    def __init__(self, device=None):
        """ä½¿ç”¨å®˜æ–¹æ–¹å¼åŠ è½½RoboPointæ¨¡å‹ - å¼ºåˆ¶å¤šGPUæ¨¡å¼è§£å†³å†…å­˜é—®é¢˜"""
        # å¼ºåˆ¶ä½¿ç”¨å¤šGPUæ¨¡å¼æ¥è§£å†³å•GPUå†…å­˜ä¸è¶³çš„é—®é¢˜
        device_map = "auto"  # è®©transformersè‡ªåŠ¨åˆ†é…å¤šGPU
        
        if isinstance(device, torch.device):
            self.device = device
        elif isinstance(device, str):
            self.device = torch.device(device if device != "auto" else "cuda:0")
        elif isinstance(device, int):
            self.device = torch.device(f"cuda:{device}")
        else:
            self.device = torch.device("cuda:0")
        
        self.model_path = "/home/fx/Exp2/test/EmbodiedEval/msjeval/model_zoo/robopoint-v1-vicuna-v1.5-13b"
        self.model_name = "RoboPoint-8B"
        self.device_map = device_map
        
        print(f"ğŸš€ åˆå§‹åŒ–TestRoboPointï¼Œå¼ºåˆ¶å¤šGPUæ¨¡å¼ device_map: {device_map}")
        print(f"ğŸ“ ä¸»è®¾å¤‡: {self.device}")
        self._load_model()
        
    def _load_model(self):
        """ä½¿ç”¨å®˜æ–¹æ–¹å¼åŠ è½½æ¨¡å‹"""
        try:
            self.tokenizer, self.model, self.image_processor, self.config = load_model_official_way(
                self.model_path, 
                self.model_name, 
                device=self.device_map
            )
            print("âœ… TestRoboPointæ¨¡å‹åŠ è½½æˆåŠŸ")
            
            # æ‰“å°è®¾å¤‡æ˜ å°„ä¿¡æ¯
            if hasattr(self.model, 'hf_device_map'):
                print("ğŸ“ æ¨¡å‹è®¾å¤‡æ˜ å°„:")
                device_info = {}
                for layer, device in self.model.hf_device_map.items():
                    if device not in device_info:
                        device_info[device] = []
                    device_info[device].append(layer)
                
                for device, layers in device_info.items():
                    print(f"   GPU {device}: {len(layers)} å±‚")
                    
        except Exception as e:
            print(f"âŒ TestRoboPointæ¨¡å‹åŠ è½½å¤±è´¥: {e}")
            raise e
    
    def move_to_device(self, device=None):
        """ç§»åŠ¨æ¨¡å‹åˆ°æŒ‡å®šè®¾å¤‡ï¼ˆå…¼å®¹æ¥å£ï¼‰- å¤šGPUæ¨¡å¼ä¸‹æ— éœ€ç§»åŠ¨"""
        # åœ¨å¤šGPUæ¨¡å¼ä¸‹ï¼Œæ¨¡å‹å·²ç»è‡ªåŠ¨åˆ†å¸ƒï¼Œæ— éœ€æ‰‹åŠ¨ç§»åŠ¨
        print(f"ğŸ“ æ¨¡å‹å·²åœ¨å¤šGPUæ¨¡å¼ä¸‹è¿è¡Œï¼Œæ— éœ€ç§»åŠ¨åˆ°è®¾å¤‡: {device}")
        pass
    
    def generate_image(self, image_list_list, question_list):
        """ç”Ÿæˆå›¾åƒå“åº” - ä½¿ç”¨å®˜æ–¹æ–¹å¼"""
        if not isinstance(image_list_list, list):
            image_list_list = [image_list_list]
        if not isinstance(question_list, list):
            question_list = [question_list]
            
        results = []
        
        for i, (images, question) in enumerate(zip(image_list_list, question_list)):
            try:
                # ä½¿ç”¨å®˜æ–¹çš„å¤„ç†æ–¹å¼
                result = self._generate_with_official_method(images, question)
                results.append(result)
                print(f"âœ… ç¬¬{i+1}ä¸ªæ ·æœ¬ç”ŸæˆæˆåŠŸ")
            except Exception as e:
                error_msg = f"Error: {str(e)}"
                results.append(error_msg)
                print(f"âŒ ç¬¬{i+1}ä¸ªæ ·æœ¬ç”Ÿæˆå¤±è´¥: {e}")
        
        return results
    
    def _generate_with_official_method(self, images, question):
        """ä½¿ç”¨å®˜æ–¹æ–¹æ³•ç”Ÿæˆå“åº”"""
        from robopoint.mm_utils import process_images, tokenizer_image_token
        from robopoint.constants import IMAGE_TOKEN_INDEX, DEFAULT_IMAGE_TOKEN
        
        # å¤„ç†å›¾åƒ
        if images is not None and len(images) > 0:
            # è½¬æ¢ä¸ºPILå›¾åƒåˆ—è¡¨
            pil_images = []
            if isinstance(images, list):
                for img in images:
                    pil_img = self._convert_to_pil(img)
                    if pil_img:
                        pil_images.append(pil_img)
            else:
                pil_img = self._convert_to_pil(images)
                if pil_img:
                    pil_images = [pil_img]
            
            if not pil_images:
                return "Error: No valid images provided"
            
            # ä½¿ç”¨å®˜æ–¹çš„process_images
            processed_images = process_images(pil_images, self.image_processor, self.model.config)
            
            # å°†å›¾åƒç§»åŠ¨åˆ°æ­£ç¡®è®¾å¤‡
            if isinstance(processed_images, list):
                processed_images = [img.to(self.model.device, dtype=torch.float16) for img in processed_images]
            else:
                processed_images = processed_images.to(self.model.device, dtype=torch.float16)
            
            # æ„å»ºå¸¦å›¾åƒtokençš„prompt
            image_tokens = DEFAULT_IMAGE_TOKEN * len(pil_images)
            prompt = f"{image_tokens}\n{question}"
            
        else:
            processed_images = None
            prompt = question
        
        # ä½¿ç”¨å®˜æ–¹çš„tokenizer_image_token
        input_ids = tokenizer_image_token(
            prompt, 
            self.tokenizer, 
            IMAGE_TOKEN_INDEX, 
            return_tensors='pt'
        ).unsqueeze(0).to(self.model.device)
        
        # ç”Ÿæˆå“åº”
        with torch.inference_mode():
            if processed_images is not None:
                output_ids = self.model.generate(
                    input_ids,
                    images=processed_images,
                    do_sample=True,
                    temperature=0.7,
                    max_new_tokens=512,
                    use_cache=True
                )
            else:
                output_ids = self.model.generate(
                    input_ids,
                    do_sample=True,
                    temperature=0.7,
                    max_new_tokens=512,
                    use_cache=True
                )
        
        # è§£ç å“åº”
        response = self.tokenizer.decode(
            output_ids[0, input_ids.shape[1]:], 
            skip_special_tokens=True
        ).strip()
        
        return response
    
    def _convert_to_pil(self, image):
        """è½¬æ¢å›¾åƒä¸ºPILæ ¼å¼"""
        try:
            if isinstance(image, str):
                # æ–‡ä»¶è·¯å¾„
                if os.path.exists(image):
                    return Image.open(image).convert('RGB')
                else:
                    print(f"âš ï¸ å›¾åƒæ–‡ä»¶ä¸å­˜åœ¨: {image}")
                    return None
            elif isinstance(image, Image.Image):
                return image.convert('RGB')
            elif isinstance(image, np.ndarray):
                return Image.fromarray(image).convert('RGB')
            elif isinstance(image, torch.Tensor):
                if image.dim() == 4:
                    image = image.squeeze(0)
                if image.dim() == 3 and image.shape[0] in [1, 3]:
                    image = image.permute(1, 2, 0)
                image_np = image.cpu().numpy()
                if image_np.dtype != np.uint8:
                    image_np = (image_np * 255).astype(np.uint8)
                return Image.fromarray(image_np).convert('RGB')
            else:
                print(f"âš ï¸ ä¸æ”¯æŒçš„å›¾åƒç±»å‹: {type(image)}")
                return None
        except Exception as e:
            print(f"âš ï¸ å›¾åƒè½¬æ¢å¤±è´¥: {e}")
            return None
    
    def clear_cache(self):
        """æ¸…ç†ç¼“å­˜"""
        if hasattr(torch.cuda, 'empty_cache'):
            torch.cuda.empty_cache()
        print("ğŸ§¹ GPUç¼“å­˜å·²æ¸…ç†")

if __name__ == "__main__":
    # æµ‹è¯•ä»£ç 
    print("ğŸš€ å¼€å§‹æµ‹è¯•RoboPoint")
    
    # åˆå§‹åŒ–æ¨¡å‹
    model = TestRoboPoint(device="auto")
    
    # æµ‹è¯•çº¯æ–‡æœ¬ç”Ÿæˆ
    result = model.generate_image([], ["Hello, how are you?"])
    print(f"ğŸ“ çº¯æ–‡æœ¬ç»“æœ: {result}")
    
    print("âœ… æµ‹è¯•å®Œæˆ") 