"""
RoboPointæµ‹è¯•ç±» - ä½¿ç”¨å®˜æ–¹å®ç°ï¼Œæ”¯æŒå¤šGPU
"""
import os
import sys
import torch
import numpy as np
from PIL import Image
import threading

class TestRoboPoint:
    def __init__(self, device=None):
        """ä½¿ç”¨å®˜æ–¹æ–¹å¼åŠ è½½RoboPointæ¨¡å‹"""
        # ç®€åŒ–deviceå¤„ç†ï¼Œç›´æ¥ä¼ ç»™å®˜æ–¹builder
        if isinstance(device, torch.device):
            device_map = f"cuda:{device.index}" if device.index is not None else "cuda:0"
            self.device = device
        elif isinstance(device, str):
            device_map = device if device in ["auto", "cpu"] else device
            self.device = torch.device(device_map if device_map != "auto" else "cuda:0")
        elif isinstance(device, int):
            device_map = f"cuda:{device}"
            self.device = torch.device(device_map)
        elif device is None:
            device_map = "auto"  # è®©transformersè‡ªåŠ¨åˆ†é…å¤šGPU
            self.device = torch.device("cuda:0")
        else:
            device_map = "auto"
            self.device = torch.device("cuda:0")
        
        self.model_path = "/home/fx/Exp2/video_model/RoboPoint-8B"
        self.model_name = "RoboPoint-8B"
        self.device_map = device_map
        
        print(f"ğŸš€ åˆå§‹åŒ–TestRoboPointï¼Œdevice_map: {device_map}")
        self._load_model()
        
    def _load_model(self):
        """ä½¿ç”¨å®˜æ–¹æ–¹å¼åŠ è½½æ¨¡å‹"""
        try:
            # å¯¼å…¥å®˜æ–¹builder
            sys.path.append('/home/fx/Exp2/video_model/RoboPoint')
            from robopoint.model.builder import load_pretrained_model
            
            # ä½¿ç”¨å®˜æ–¹çš„load_pretrained_modelå‡½æ•°
            self.tokenizer, self.model, self.image_processor, context_len = load_pretrained_model(
                model_path=self.model_path,
                model_base=None,
                model_name=self.model_name,
                load_8bit=False,
                load_4bit=False,
                device_map=self.device_map,  # "auto" æˆ–å…·ä½“è®¾å¤‡
                device="cuda",
                use_flash_attn=False
            )
            
            self.context_len = context_len
            print("âœ… TestRoboPointæ¨¡å‹åŠ è½½æˆåŠŸ")
            
            # æ‰“å°è®¾å¤‡æ˜ å°„ä¿¡æ¯
            if hasattr(self.model, 'hf_device_map'):
                print("ğŸ“ æ¨¡å‹è®¾å¤‡æ˜ å°„:")
                device_info = {}
                for layer, device in self.model.hf_device_map.items():
                    if device not in device_info:
                        device_info[device] = []
                    device_info[device].append(layer)
                
                for device, layers in device_info.items():
                    print(f"   GPU {device}: {len(layers)} å±‚")
                    
        except Exception as e:
            print(f"âŒ TestRoboPointæ¨¡å‹åŠ è½½å¤±è´¥: {e}")
            raise e
    
    def generate_image(self, image_list_list, question_list):
        """ç”Ÿæˆå›¾åƒå“åº” - ä½¿ç”¨å®˜æ–¹æ–¹å¼"""
        if not isinstance(image_list_list, list):
            image_list_list = [image_list_list]
        if not isinstance(question_list, list):
            question_list = [question_list]
            
        results = []
        
        for i, (images, question) in enumerate(zip(image_list_list, question_list)):
            try:
                # ä½¿ç”¨å®˜æ–¹çš„å¤„ç†æ–¹å¼
                result = self._generate_with_official_method(images, question)
                results.append(result)
                print(f"âœ… ç¬¬{i+1}ä¸ªæ ·æœ¬ç”ŸæˆæˆåŠŸ")
            except Exception as e:
                error_msg = f"Error: {str(e)}"
                results.append(error_msg)
                print(f"âŒ ç¬¬{i+1}ä¸ªæ ·æœ¬ç”Ÿæˆå¤±è´¥: {e}")
        
        return results
    
    def _generate_with_official_method(self, images, question):
        """ä½¿ç”¨å®˜æ–¹æ–¹æ³•ç”Ÿæˆå“åº”"""
        from robopoint.mm_utils import process_images, tokenizer_image_token
        from robopoint.constants import IMAGE_TOKEN_INDEX, DEFAULT_IMAGE_TOKEN
        
        # å¤„ç†å›¾åƒ
        if images is not None and len(images) > 0:
            # è½¬æ¢ä¸ºPILå›¾åƒåˆ—è¡¨
            pil_images = []
            if isinstance(images, list):
                for img in images:
                    pil_img = self._convert_to_pil(img)
                    if pil_img:
                        pil_images.append(pil_img)
            else:
                pil_img = self._convert_to_pil(images)
                if pil_img:
                    pil_images = [pil_img]
            
            if not pil_images:
                return "Error: No valid images provided"
            
            # ä½¿ç”¨å®˜æ–¹çš„process_images
            processed_images = process_images(pil_images, self.image_processor, self.model.config)
            
            # å°†å›¾åƒç§»åŠ¨åˆ°æ­£ç¡®è®¾å¤‡
            if isinstance(processed_images, list):
                processed_images = [img.to(self.model.device, dtype=torch.float16) for img in processed_images]
            else:
                processed_images = processed_images.to(self.model.device, dtype=torch.float16)
            
            # æ„å»ºå¸¦å›¾åƒtokençš„prompt
            image_tokens = DEFAULT_IMAGE_TOKEN * len(pil_images)
            prompt = f"{image_tokens}\n{question}"
            
        else:
            processed_images = None
            prompt = question
        
        # ä½¿ç”¨å®˜æ–¹çš„tokenizer_image_token
        input_ids = tokenizer_image_token(
            prompt, 
            self.tokenizer, 
            IMAGE_TOKEN_INDEX, 
            return_tensors='pt'
        ).unsqueeze(0).to(self.model.device)
        
        # ç”Ÿæˆå“åº”
        with torch.inference_mode():
            if processed_images is not None:
                output_ids = self.model.generate(
                    input_ids,
                    images=processed_images,
                    do_sample=True,
                    temperature=0.7,
                    max_new_tokens=512,
                    use_cache=True
                )
            else:
                output_ids = self.model.generate(
                    input_ids,
                    do_sample=True,
                    temperature=0.7,
                    max_new_tokens=512,
                    use_cache=True
                )
        
        # è§£ç å“åº”
        response = self.tokenizer.decode(
            output_ids[0, input_ids.shape[1]:], 
            skip_special_tokens=True
        ).strip()
        
        return response
    
    def _convert_to_pil(self, image):
        """è½¬æ¢å›¾åƒä¸ºPILæ ¼å¼"""
        try:
            if isinstance(image, str):
                # æ–‡ä»¶è·¯å¾„
                if os.path.exists(image):
                    return Image.open(image).convert('RGB')
                else:
                    print(f"âš ï¸ å›¾åƒæ–‡ä»¶ä¸å­˜åœ¨: {image}")
                    return None
            elif isinstance(image, Image.Image):
                return image.convert('RGB')
            elif isinstance(image, np.ndarray):
                return Image.fromarray(image).convert('RGB')
            elif isinstance(image, torch.Tensor):
                if image.dim() == 4:
                    image = image.squeeze(0)
                if image.dim() == 3 and image.shape[0] in [1, 3]:
                    image = image.permute(1, 2, 0)
                image_np = image.cpu().numpy()
                if image_np.dtype != np.uint8:
                    image_np = (image_np * 255).astype(np.uint8)
                return Image.fromarray(image_np).convert('RGB')
            else:
                print(f"âš ï¸ ä¸æ”¯æŒçš„å›¾åƒç±»å‹: {type(image)}")
                return None
        except Exception as e:
            print(f"âš ï¸ å›¾åƒè½¬æ¢å¤±è´¥: {e}")
            return None
    
    def clear_cache(self):
        """æ¸…ç†ç¼“å­˜"""
        if hasattr(torch.cuda, 'empty_cache'):
            torch.cuda.empty_cache()
        print("ğŸ§¹ GPUç¼“å­˜å·²æ¸…ç†")

if __name__ == "__main__":
    # æµ‹è¯•ä»£ç 
    print("ğŸš€ å¼€å§‹æµ‹è¯•RoboPoint")
    
    # åˆå§‹åŒ–æ¨¡å‹
    model = TestRoboPoint(device="auto")
    
    # æµ‹è¯•çº¯æ–‡æœ¬ç”Ÿæˆ
    result = model.generate_image([], ["Hello, how are you?"])
    print(f"ğŸ“ çº¯æ–‡æœ¬ç»“æœ: {result}")
    
    print("âœ… æµ‹è¯•å®Œæˆ") 